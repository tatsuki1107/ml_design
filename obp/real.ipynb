{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7134150-c7f2-424f-af86-b4ead6eabdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なパッケージをインポート\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import obp\n",
    "from obp.dataset import OpenBanditDataset\n",
    "from obp.policy import IPWLearner\n",
    "from obp.ope import (\n",
    "    OffPolicyEvaluation, \n",
    "    RegressionModel,\n",
    "    InverseProbabilityWeighting as IPS,\n",
    "    DoublyRobust as DR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee8eb3f-b6e5-4068-8585-b563c0550a98",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b75990-8cbd-405e-b2af-e0b2c12ee975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/mldesign-9TtSrW0h-py3.9/lib/python3.9/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['n_rounds', 'n_actions', 'action', 'position', 'reward', 'pscore', 'context', 'action_context'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ZOZOTOWNのトップページ推薦枠でBernoulli Thompson Sampling (bts)が収集したデータをダウンロードする\n",
    "# `data_path=None`とすると、スモールサイズのお試しデータセットを用いることができる\n",
    "dataset = OpenBanditDataset(\n",
    "    behavior_policy=\"bts\", #データ収集に用いられた意思決定モデル\n",
    "    campaign=\"men\", #キャンペーン \"men\",\"women\"\n",
    "    data_path=Path(\"./open_bandit_dataset\"), #データセットのパス\n",
    ")\n",
    "\n",
    "# デフォルトの前処理を施したデータを取得する\n",
    "# タイムスタンプの前半70%をトレーニングデータ、後半30%をバリデーションデータとする\n",
    "train_data, validation_data = dataset.obtain_batch_bandit_feedback(\n",
    "    test_size=0.3,\n",
    "    is_timeseries_split=True\n",
    ")\n",
    "\n",
    "train_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2f2ba7-186e-4859-952a-ab7370f44872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 行動（ファッションアイテム）の数\n",
    "dataset.n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "900a3e8e-1401-450b-b87f-a337c6255518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4077727"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データ数\n",
    "dataset.n_rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "896e494f-d7f8-41ba-993d-62e94b262a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デフォルトの前処理による特徴料の次元数\n",
    "dataset.dim_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1032a343-788a-40c4-a87a-7a37ec661a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推薦枠におけるポジションの数\n",
    "dataset.len_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6f4f7-5a05-4be7-be21-cfa95b2b3600",
   "metadata": {},
   "source": [
    "# 意思決定モデルの学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241f7a1-391f-4e4b-9985-ff93729e72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内部で用いる分類器としてRandomForestを指定したIPWLearnerを定義する\n",
    "new_decision_making_model = IPWLearner(\n",
    "    n_actions=dataset.n_actions, #行動の数\n",
    "    len_list=dataset.len_list, #推薦枠の数\n",
    "    base_classifier=RandomForestClassifier(\n",
    "        n_estimators=300, max_depth=10, min_samples_leaf=5, random_state=12345\n",
    "    ),\n",
    ")\n",
    "\n",
    "#trainデータを用いて、意思決定モデルを学習する\n",
    "new_decision_making_model.fit(\n",
    "    context=train_data[\"context\"], #特徴量(X_i)\n",
    "    action=train_data[\"action\"], #過去の意思決定モデルによる行動選択\n",
    "    reward=train_data[\"reward\"], #観測される目的変数\n",
    "    position=train_data[\"position\"], #行動が提示された推薦位置\n",
    "    pscore=train_data[\"pscore\"], #過去の意思決定モデルによる行動選択確率\n",
    ")\n",
    "\n",
    "#validationデータに対して行動を選択\n",
    "action_dist = new_decision_making_model.predict(\n",
    "    context=validation_data[\"context\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389848e8-04cc-4cd1-bb29-497a0d6cbf6d",
   "metadata": {},
   "source": [
    "# 意思決定モデルの性能評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946185d-1cc4-4164-b747-b18a3b8e5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DR推定量を用いるのに必要な目的変数予測モデルを得る\n",
    "# opeモジュールに実装されている`RegressionModel`に好みの機械学習手法を与えば良い\n",
    "regression_model = RegressionModel(\n",
    "    n_actions_dataset.n_actions, #行動の数\n",
    "    len_list=dataset.len_list, #推薦枠内のポジション数\n",
    "    base_model=LogisticRegression(C=100, max_iter=10000, random_state=12345)\n",
    ")\n",
    "\n",
    "# `fit_predict`メソッドにより、バリデーションデータにおける期待報酬を推定\n",
    "estimated_rewards_by_reg_model = regression_model.fit_predict(\n",
    "    context=validation_data[\"context\"], #特徴量(X_i)\n",
    "    action=validation_data[\"action\"], #過去の意思決定モデルによる行動選択\n",
    "    reward=validation_data[\"reward\"], #観測される目的変数\n",
    "    position=validation_data[\"position\"], #行動が提示された推薦位置\n",
    "    random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043f24d-3b37-4492-a0ac-74b4eeaf595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 意思決定モデルの性能評価を一気通貫で行うための`OffPolicyEvaluation`を定義する\n",
    "ope = OffPolicyEvaluation(\n",
    "    bandit_feedback=validation_data, #バリデーションデータ\n",
    "    ope_estimators=[IPS(), DR()] #使用する推定量\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb451b5a-a6c6-4676-a40a-a9e6865b3a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内部で用いる分類器としてロジスティック回帰を指定したIPWLearnerの性能をOPEにより評価\n",
    "ope.visualize_off_policy_estimates(\n",
    "    action_dist=action_dist, #evaluation_policy_aによるバリデーションデータに対する行動選択\n",
    "    estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
    "    is_relative=True, #過去の意思決定モデルの性能に対する相対的な改善率を出力\n",
    "    random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a701061-fcfa-49f8-98f9-cf22863bf698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
